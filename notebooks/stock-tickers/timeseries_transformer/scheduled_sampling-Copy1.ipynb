{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8190d02e-f5a6-4ad8-b998-34a80650067b",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7e931d2-80fe-4728-8836-9215fa3dcb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Training Parameters\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Dataset Parameters\n",
    "dataset_daily_frequency = 24 # 24 corresponds to hourly data\n",
    "target_col_name = \"FCR_N_PriceEUR\"\n",
    "timestamp_col = \"timestamp\"\n",
    "cutoff_date = datetime.datetime(2017, 1, 1)\n",
    "\n",
    "# Scheduled Sampling Parameters\n",
    "x_mid = round(epochs * 0.55) # shift=0.5 converges f(midpoint) = 0.5; shifts scheduled_sampling_ratio curve further/closer from end of dataset\n",
    "start_scheduled_sampling_epoch = round(epochs * 0.2) # Adjust this value to start scheduled sampling after a certain epoch\n",
    "k = 0.3\n",
    "\n",
    "# Model Parameters\n",
    "dim_val = 512\n",
    "n_heads = 8\n",
    "n_decoder_layers = 4\n",
    "n_encoder_layers = 4\n",
    "dec_seq_len = 2 * dataset_daily_frequency\n",
    "enc_seq_len = 8 * dataset_daily_frequency # supposing you want the model to base its forecasts on the previous X days of data\n",
    "output_sequence_length = 2 * dataset_daily_frequency # target sequence length. If hourly data and length = 48, you predict 2 days ahead\n",
    "step_size = 1\n",
    "batch_first = False\n",
    "num_predicted_features = 1\n",
    "\n",
    "# Hyperparameters\n",
    "test_size = 0.15\n",
    "validation_size = 0.15\n",
    "forecast_window = 2 * dataset_daily_frequency # supposing you're forecasting 48 hours ahead\n",
    "batch_size = 4 * forecast_window # 1280\n",
    "window_size = enc_seq_len + output_sequence_length # used to slice data into sub-sequences\n",
    "\n",
    "# Define input variables\n",
    "exogenous_vars = []\n",
    "input_variables = [target_col_name] + exogenous_vars\n",
    "input_size = len(input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f440da-5510-4fb0-a6df-70e2af48adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scheduled sampling function (Sigmoid decay curve)\n",
    "def sigmoid_decay(x, x_mid, x_max, start_scheduled_sampling_epoch):\n",
    "    # Sigmoid function with scaling and shifting\n",
    "    return 1 / (1 + np.exp(-(x - start_scheduled_sampling_epoch - x_mid) / (k * (x_max - x_mid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de19dba4-64f2-4f63-a5ce-7d04f66053a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate x values\n",
    "x_values = np.linspace(0, epochs)\n",
    "\n",
    "# Calculate y values using the sigmoid decay function\n",
    "y_values = sigmoid_decay(x_values, x_mid, epochs, start_scheduled_sampling_epoch)\n",
    "\n",
    "# Plot the curve\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Scheduled Sample Ratio')\n",
    "plt.title('Scheduled Sample Ratio')\n",
    "plt.grid(True)\n",
    "plt.axvline(x=start_scheduled_sampling_epoch, color='red', linestyle='dotted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b89b6d-f8b8-4ac6-930c-905e82378e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file in data/dfs_merged_upload.csv\n",
      "From get_src_trg: data size = torch.Size([32189, 1])\n",
      "From get_src_trg: data size = torch.Size([6898, 1])\n",
      "From get_src_trg: data size = torch.Size([6898, 1])\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import dataset as ds\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Read data\n",
    "data = utils.read_data('dfs_merged_upload')\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "train_split_idx = round(len(data) * (1 - test_size - validation_size))\n",
    "validation_split_idx = round(len(data) * (1 - test_size))\n",
    "training_data_raw = data[:train_split_idx]\n",
    "validation_data_raw = data[train_split_idx:validation_split_idx]\n",
    "test_data_raw = data[validation_split_idx:]\n",
    "\n",
    "# Get training indices\n",
    "training_indices = utils.get_indices_entire_sequence(\n",
    "    data=training_data_raw,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size)\n",
    "\n",
    "# Get validation indices\n",
    "validation_indices = utils.get_indices_entire_sequence(\n",
    "    data=validation_data_raw,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size)\n",
    "\n",
    "# Get test indices\n",
    "test_indices = utils.get_indices_entire_sequence(\n",
    "    data=test_data_raw,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size)\n",
    "\n",
    "# Create custom dataset class for training data\n",
    "training_data = ds.TransformerDataset(\n",
    "    data=torch.tensor(training_data_raw[input_variables].values).float(),\n",
    "    indices=training_indices,\n",
    "    enc_seq_len=enc_seq_len,\n",
    "    dec_seq_len=dec_seq_len,\n",
    "    target_seq_len=output_sequence_length)\n",
    "\n",
    "# Create custom dataset class for validation data\n",
    "validation_data = ds.TransformerDataset(\n",
    "    data=torch.tensor(validation_data_raw[input_variables].values).float(),\n",
    "    indices=validation_indices,\n",
    "    enc_seq_len=enc_seq_len,\n",
    "    dec_seq_len=dec_seq_len,\n",
    "    target_seq_len=output_sequence_length)\n",
    "\n",
    "# Create custom dataset class for test data\n",
    "test_data = ds.TransformerDataset(\n",
    "    data=torch.tensor(test_data_raw[input_variables].values).float(),\n",
    "    indices=test_indices,\n",
    "    enc_seq_len=enc_seq_len,\n",
    "    dec_seq_len=dec_seq_len,\n",
    "    target_seq_len=output_sequence_length)\n",
    "\n",
    "# Create DataLoader for training data\n",
    "training_dataloader = DataLoader(training_data, batch_size)\n",
    "\n",
    "# Create DataLoader for validation data\n",
    "validation_dataloader = DataLoader(validation_data, batch_size)\n",
    "\n",
    "# Create DataLoader for test data\n",
    "test_dataloader = DataLoader(test_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d726466b-7afa-451f-80f8-cf4ee50171c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_timeseries as tst\n",
    "\n",
    "# Initialize model\n",
    "model = tst.TimeSeriesTransformer(\n",
    "    input_size=input_size,\n",
    "    dec_seq_len=dec_seq_len,\n",
    "    batch_first=batch_first,\n",
    "    num_predicted_features=num_predicted_features,\n",
    "    dim_val=dim_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a633b348-07ca-49cf-b454-05eb28813a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, training_dataloader, optimizer, loss_function, scheduled_sampling_ratio):\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "\n",
    "    for i, batch in enumerate(training_dataloader):\n",
    "        src, trg, trg_y = batch\n",
    "\n",
    "        # Scheduled sampling\n",
    "        if scheduled_sampling_ratio > np.random.rand():\n",
    "            trg = trg_y\n",
    "\n",
    "        # Permute shape if needed\n",
    "        if not batch_first:\n",
    "            src = src.permute(1, 0, 2)\n",
    "            trg = trg.permute(1, 0, 2)\n",
    "            trg_y = trg_y.permute(1, 0, 2)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Generate masks\n",
    "        trg_mask = utils.generate_square_subsequent_mask(\n",
    "            dim1=forecast_window,\n",
    "            dim2=forecast_window,\n",
    "            device=device\n",
    "        )\n",
    "        src_mask = utils.generate_square_subsequent_mask(\n",
    "            dim1=forecast_window,\n",
    "            dim2=enc_seq_len,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Make forecasts\n",
    "        prediction = model(src, trg, src_mask, trg_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(trg_y, prediction)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Take optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Append to training loss history\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        print(f\"Epoch: {epoch}/{epochs}, Batch: {i}/{len(training_dataloader)}, Loss: {loss.item()} Scheduled Sampling Ratio: {scheduled_sampling_ratio}\")\n",
    "        \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9bf6f1f-d610-4d30-ad37-a558231f401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Put model in evaluation mode, calculate average loss across validation dataset.\n",
    "\"\"\"\n",
    "def validate_model(device, model, validation_dataloader, loss_function):\n",
    "        model.eval()\n",
    "        \n",
    "        loss_history = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (src, _, trg_y) in enumerate(validation_dataloader):\n",
    "\n",
    "                prediction = inference.run_encoder_decoder_inference(\n",
    "                    model=model, \n",
    "                    src=src.to(device), \n",
    "                    forecast_window=forecast_window,\n",
    "                    batch_size=src.shape[1],\n",
    "                    device=device\n",
    "                )\n",
    "                \n",
    "                # trg_y = trg_y.permute(1, 0).unsqueeze(-1)  # Shape becomes [48, 256, 1]\n",
    "\n",
    "                # print(f\"Shape of prediction: {prediction.shape}\")\n",
    "                # print(f\"Shape of target: {trg_y.shape}\")\n",
    "                # print(f\"Shape of src: {src.shape}\")\n",
    "\n",
    "\n",
    "                loss = loss_function(trg_y, prediction)\n",
    "                loss_history.append(loss.item())\n",
    "\n",
    "        return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1711328-576b-4c7c-afa1-4ada48284731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10, Batch: 0/167, Loss: 678.0043334960938 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 1/167, Loss: 194.7345428466797 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 2/167, Loss: 100.60458374023438 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 3/167, Loss: 77.62813568115234 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 4/167, Loss: 40.61069869995117 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 5/167, Loss: 94.7666244506836 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 6/167, Loss: 68.90487670898438 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 7/167, Loss: 72.14118957519531 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 8/167, Loss: 261.69696044921875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 9/167, Loss: 149.279296875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 10/167, Loss: 181.6450958251953 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 11/167, Loss: 306.99468994140625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 12/167, Loss: 299.2161560058594 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 13/167, Loss: 328.1376037597656 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 14/167, Loss: 537.409912109375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 15/167, Loss: 485.4107971191406 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 16/167, Loss: 299.3215637207031 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 17/167, Loss: 351.0550842285156 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 18/167, Loss: 632.5948486328125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 19/167, Loss: 623.2847900390625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 20/167, Loss: 620.8746948242188 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 21/167, Loss: 357.6578369140625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 22/167, Loss: 265.64373779296875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 23/167, Loss: 216.84307861328125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 24/167, Loss: 151.64488220214844 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 25/167, Loss: 191.76739501953125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 26/167, Loss: 247.6859893798828 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 27/167, Loss: 201.15896606445312 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 28/167, Loss: 128.669189453125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 29/167, Loss: 91.22602844238281 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 30/167, Loss: 93.58565521240234 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 31/167, Loss: 117.08543395996094 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 32/167, Loss: 195.31509399414062 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 33/167, Loss: 255.52549743652344 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 34/167, Loss: 145.71278381347656 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 35/167, Loss: 107.99629211425781 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 36/167, Loss: 154.9344024658203 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 37/167, Loss: 113.99522399902344 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 38/167, Loss: 115.74541473388672 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 39/167, Loss: 111.8605728149414 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 40/167, Loss: 87.75919342041016 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 41/167, Loss: 78.49186706542969 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 42/167, Loss: 37.89854431152344 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 43/167, Loss: 240.55963134765625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 44/167, Loss: 53.31817626953125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 45/167, Loss: 45.22062683105469 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 46/167, Loss: 37.85707092285156 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 47/167, Loss: 33.035888671875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 48/167, Loss: 31.87506103515625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 49/167, Loss: 27.098865509033203 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 50/167, Loss: 13.566336631774902 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 51/167, Loss: 10.871397018432617 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 52/167, Loss: 2.613156318664551 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 53/167, Loss: 1.8478628396987915 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 54/167, Loss: 3.430695056915283 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 55/167, Loss: 10.02269458770752 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 56/167, Loss: 42.38716506958008 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 57/167, Loss: 142.24392700195312 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 58/167, Loss: 201.34898376464844 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 59/167, Loss: 156.3444366455078 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 60/167, Loss: 637.240234375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 61/167, Loss: 1237.904296875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 62/167, Loss: 793.41015625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 63/167, Loss: 453.8509826660156 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 64/167, Loss: 258.8683166503906 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 65/167, Loss: 555.0194091796875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 66/167, Loss: 1003.3211669921875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 67/167, Loss: 867.274658203125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 68/167, Loss: 1043.6131591796875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 69/167, Loss: 1486.4066162109375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 70/167, Loss: 4160.88525390625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 71/167, Loss: 5667.361328125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 72/167, Loss: 7548.486328125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 73/167, Loss: 1681.952880859375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 74/167, Loss: 353.1690368652344 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 75/167, Loss: 200.4902801513672 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 76/167, Loss: 423.68560791015625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 77/167, Loss: 1029.4949951171875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 78/167, Loss: 1311.0086669921875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 79/167, Loss: 385.77093505859375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 80/167, Loss: 514.5885009765625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 81/167, Loss: 726.6448974609375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 82/167, Loss: 304.8726501464844 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 83/167, Loss: 179.510009765625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 84/167, Loss: 178.5614471435547 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 85/167, Loss: 183.1808624267578 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 86/167, Loss: 225.6180419921875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 87/167, Loss: 219.0819854736328 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 88/167, Loss: 247.16168212890625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 89/167, Loss: 213.12779235839844 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 90/167, Loss: 253.5618438720703 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 91/167, Loss: 174.2437744140625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 92/167, Loss: 156.03536987304688 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 93/167, Loss: 162.58460998535156 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 94/167, Loss: 140.58998107910156 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 95/167, Loss: 158.0436553955078 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 96/167, Loss: 129.61917114257812 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 97/167, Loss: 111.85602569580078 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 98/167, Loss: 133.5753631591797 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 99/167, Loss: 224.30331420898438 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 100/167, Loss: 257.3038635253906 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 101/167, Loss: 488.0848693847656 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 102/167, Loss: 314.0442810058594 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 103/167, Loss: 127.8503189086914 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 104/167, Loss: 475.10882568359375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 105/167, Loss: 1135.6678466796875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 106/167, Loss: 623.5032958984375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 107/167, Loss: 283.7474670410156 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 108/167, Loss: 347.95013427734375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 109/167, Loss: 175.67369079589844 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 110/167, Loss: 127.456787109375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 111/167, Loss: 103.82472229003906 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 112/167, Loss: 47.88106155395508 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 113/167, Loss: 48.03023147583008 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 114/167, Loss: 109.12381744384766 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 115/167, Loss: 159.5909881591797 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 116/167, Loss: 137.41102600097656 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 117/167, Loss: 188.7685089111328 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 118/167, Loss: 180.5601348876953 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 119/167, Loss: 240.05328369140625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 120/167, Loss: 349.4324035644531 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 121/167, Loss: 291.86761474609375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 122/167, Loss: 319.5124816894531 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 123/167, Loss: 217.58444213867188 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 124/167, Loss: 161.46002197265625 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 125/167, Loss: 155.7646942138672 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 126/167, Loss: 207.0037078857422 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 127/167, Loss: 251.76060485839844 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 128/167, Loss: 202.68942260742188 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 129/167, Loss: 123.63072204589844 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 130/167, Loss: 103.62966918945312 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 131/167, Loss: 70.09394836425781 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 132/167, Loss: 59.73324966430664 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 133/167, Loss: 63.17392349243164 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 134/167, Loss: 61.52729034423828 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 135/167, Loss: 473.7060546875 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 136/167, Loss: 648.4089965820312 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 137/167, Loss: 214.08468627929688 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 138/167, Loss: 100.26748657226562 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 139/167, Loss: 42.21221160888672 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 140/167, Loss: 55.65882873535156 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 141/167, Loss: 38.57618713378906 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 142/167, Loss: 32.59928512573242 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 143/167, Loss: 30.94561195373535 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 144/167, Loss: 46.891971588134766 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 145/167, Loss: 57.9805908203125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 146/167, Loss: 58.29110336303711 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 147/167, Loss: 62.91975402832031 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 148/167, Loss: 67.93067932128906 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 149/167, Loss: 54.53575134277344 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 150/167, Loss: 31.981245040893555 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 151/167, Loss: 8.226912498474121 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 152/167, Loss: 3.2189526557922363 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 153/167, Loss: 36.77908706665039 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 154/167, Loss: 151.47784423828125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 155/167, Loss: 235.197021484375 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 156/167, Loss: 145.19876098632812 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 157/167, Loss: 115.20616149902344 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 158/167, Loss: 103.36933135986328 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 159/167, Loss: 111.82369232177734 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 160/167, Loss: 55.54536819458008 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 161/167, Loss: 18.92764663696289 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 162/167, Loss: 12.392662048339844 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 163/167, Loss: 36.0186767578125 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 164/167, Loss: 43.44374465942383 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 165/167, Loss: 9.073081016540527 Scheduled Sampling Ratio: 0.0\n",
      "Epoch: 0/10, Batch: 166/167, Loss: 15.489189147949219 Scheduled Sampling Ratio: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryneschroder/miniconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([48, 192, 1])) that is different to the input size (torch.Size([192, 48, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (48) must match the size of tensor b (192) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m training_loss_history \u001b[38;5;241m=\u001b[39m train_model(model, training_dataloader, optimizer, loss_function, scheduled_sampling_ratio)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Validation phase  \u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m validation_loss_history \u001b[38;5;241m=\u001b[39m validate_model(device, model, validation_dataloader, loss_function)\n\u001b[1;32m     45\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Average Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(training_loss_history)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(training_loss_history)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Average Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(validation_loss_history)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(validation_loss_history)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Time (s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(device, model, validation_dataloader, loss_function)\u001b[0m\n\u001b[1;32m     12\u001b[0m         prediction \u001b[38;5;241m=\u001b[39m inference\u001b[38;5;241m.\u001b[39mrun_encoder_decoder_inference(\n\u001b[1;32m     13\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[1;32m     14\u001b[0m             src\u001b[38;5;241m=\u001b[39msrc\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m             device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     18\u001b[0m         )\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# trg_y = trg_y.permute(1, 0).unsqueeze(-1)  # Shape becomes [48, 256, 1]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m         \u001b[38;5;66;03m# print(f\"Shape of prediction: {prediction.shape}\")\u001b[39;00m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;66;03m# print(f\"Shape of target: {trg_y.shape}\")\u001b[39;00m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# print(f\"Shape of src: {src.shape}\")\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_function(trg_y, prediction)\n\u001b[1;32m     28\u001b[0m         loss_history\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_history\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmse_loss(\u001b[38;5;28minput\u001b[39m, target, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3292\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m   3295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mbroadcast_tensors(tensors)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (48) must match the size of tensor b (192) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Demonstrating how to use the transformer model with time-series data.\n",
    "This code includes a full training loop with scheduled sampling and an evaluation step.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import inference\n",
    "from accelerate import Accelerator\n",
    "import time\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loss_history = []\n",
    "validation_loss_history = []\n",
    "\n",
    "# Prepare device\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "model, optimizer, training_dataloader = accelerator.prepare(\n",
    "    model,\n",
    "    optimizer,\n",
    "    training_dataloader,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "training_loss_history = []\n",
    "validation_loss_history = []\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Scheduled Sampling\n",
    "    if epoch >= start_scheduled_sampling_epoch:\n",
    "        scheduled_sampling_ratio = sigmoid_decay(epoch, x_mid, epochs, start_scheduled_sampling_epoch)\n",
    "    else:\n",
    "        scheduled_sampling_ratio = 0.0  # Use teacher-forcing before start_scheduled_sampling_epoch\n",
    "    \n",
    "    # Training Phase    \n",
    "    training_loss_history = train_model(model, training_dataloader, optimizer, loss_function, scheduled_sampling_ratio)\n",
    "      \n",
    "    # Validation phase  \n",
    "    validation_loss_history = validate_model(device, model, validation_dataloader, loss_function)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Epoch: {epoch}, Average Training Loss: {sum(training_loss_history) / len(training_loss_history)} Average Validation Loss: {sum(validation_loss_history) / len(validation_loss_history)} Time (s): {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a12fe-28a6-4fa3-aba3-0370beae4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# view training\n",
    "training_loss_history = np.array(training_loss_history).reshape(-1)\n",
    "x = range(training_loss_history.shape[0])\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x, training_loss_history, label=\"train\")\n",
    "plt.title(\"Loss\", fontsize=15)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"nll\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0846f985-879c-4b62-9970-2d2ce39936a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a583996-0674-418f-96b1-b2abb54302de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "forecasts_ = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    outputs = model.generate(\n",
    "        static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "        if config.num_static_categorical_features > 0\n",
    "        else None,\n",
    "        static_real_features=batch[\"static_real_features\"].to(device)\n",
    "        if config.num_static_real_features > 0\n",
    "        else None,\n",
    "        past_time_features=batch[\"past_time_features\"].to(device),\n",
    "        past_values=batch[\"past_values\"].to(device),\n",
    "        future_time_features=batch[\"future_time_features\"].to(device),\n",
    "        past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "    )\n",
    "    forecasts_.append(outputs.sequences.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e4b0e-e411-49d6-9a7d-35b9250b40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda6807-9beb-4cc3-a3d6-564688aba12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = np.vstack(forecasts_)\n",
    "print(forecasts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79061d95-b923-4de9-a1b2-8a129345cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from gluonts.time_feature import get_seasonality\n",
    "\n",
    "mase_metric = load(\"evaluate-metric/mase\")\n",
    "smape_metric = load(\"evaluate-metric/smape\")\n",
    "\n",
    "forecast_median = np.median(forecasts, 1).squeeze(0).T\n",
    "\n",
    "mase_metrics = []\n",
    "smape_metrics = []\n",
    "\n",
    "for item_id, ts in enumerate(test_data):\n",
    "    training_data = ts[\"target\"][:-prediction_length]\n",
    "    ground_truth = ts[\"target\"][-prediction_length:]\n",
    "    mase = mase_metric.compute(\n",
    "        predictions=forecast_median[item_id],\n",
    "        references=np.array(ground_truth),\n",
    "        training=np.array(training_data),\n",
    "        periodicity=get_seasonality(freq),\n",
    "    )\n",
    "    mase_metrics.append(mase[\"mase\"])\n",
    "\n",
    "    smape = smape_metric.compute(\n",
    "        predictions=forecast_median[item_id],\n",
    "        references=np.array(ground_truth),\n",
    "    )\n",
    "    smape_metrics.append(smape[\"smape\"])\n",
    "    \n",
    "print(f\"MASE: {np.mean(mase_metrics)}\")\n",
    "print(f\"sMAPE: {np.mean(smape_metrics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6291d69-f6b9-4247-8ee5-240536a6f0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
